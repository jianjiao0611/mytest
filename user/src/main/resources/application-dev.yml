server:
  port: 8004
spring:
  redis:
    host: localhost
    port: 6379
    password:
    jedis:
      pool:
        # 连接池最大连接数（使用负值表示没有限制）
        max-active: 20
        # 连接池最大阻塞等待时间
        max-wait: 30s
        # 连接池中的最大空闲连接
        max-idle: 8
        # 连接池中的最小空闲连接
        min-idle: 1
    # 连接超时时间
    timeout: 1000
  application:
    name: user
  datasource:
    druid:

      url: jdbc:mysql://127.0.0.1:3306/jjtest_user?useUnicode=true&characterEncoding=utf8&characterSetResults=utf8&serverTimezone=Asia/Shanghai
      username: root
      password: 123456
      driver-class-name: com.mysql.jdbc.Driver
      db-type: com.alibaba.druid.pool.DruidDataSource
      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      useGlobalDataSourceStat: true
      log-abandoned: true
      #      filter:
      #        stat:
      #          log-slow-sql: true
      # 初始化大小，最小，最大
      initialSize: 2
      minIdle: 2
      maxActive: 10
      # 配置获取连接等待超时的时间
      maxWait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      timeBetweenEvictionRunsMillis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 1 FROM DUAL
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20

      webStatFilter:
        enabled: true
      statViewServlet:
        enabled: true
        # 设置白名单，不填则允许所有访问
        allow:
        url-pattern: /druid/*
        # 控制台管理用户名和密码
        login-username:
        login-password:
      filter:
        stat:
          enabled: true
          # 慢SQL记录
          log-slow-sql: true
          slow-sql-millis: 1000
          merge-sql: true
        wall:
          config:
            multi-statement-allow: true

  kafka:
    bootstrap-servers: 127.0.0.1:9092
    listener:
      concurrency: 9
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      acks: all
        # 设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。
      # 允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
      retries: 0
      client-id: user
    consumer:
      group-id: user
      # 是否自动提交offset
      enable-auto-commit: false
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      # 提交offset延时(接收到消息后多久提交offset)
      #      auto-commit-interval: 100ms
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
mybatis:
  mapper-locations: classpath*:/mapper/**.xml   #把xml文件放在com.XX.mapper.*中可能会出现找到的问题，这里把他放在resource下的mapper中
  #  typeAliasesPackage: com.tustore.taskcenter.entity #这里是实体类的位置 多个package用逗号或者分号分隔
  configuration:
    log-impl: com.jjtest.tool.log.TuStoreOutImpl
    lazyLoadingEnabled: false #延时加载的开关
    map-underscore-to-camel-case: true
    cache-enabled: false

eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:8000/eureka
    register-with-eureka: true
    fetch-registry: true
  instance:
    preferIpAddress: true
    instance-id: ${spring.cloud.client.ipAddress}:${server.port}

# 日志配置
logging:
  level:
    com.*: debug
    org.springframework: warn
  config: classpath:logback.xml

#异步线程配置
async:
  threadpool:
    param:
      config:
        filepyncpool: '{"coreSize":10,"maxSize":100,"queueCapacity":100,"keepAliveSeconds":60}'
      list:
      - 1
      - 2
      - 3

usernamae: ${localIp:127.0.0.1}
password: ${localport:1}
testff: \{"userName":"jj","age":21\}